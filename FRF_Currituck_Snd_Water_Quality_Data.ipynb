{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRF_Currituck Sound Water Quality Data\n",
    "\n",
    "Reading the FRF Thredds Server netCDF data for various water quality variables recorded in the Currituck Sound and writing these data, or a subset thereof, to a comma-separated values file. \n",
    "\n",
    "What data?\n",
    "\n",
    "- time (converted to ISO 8601 format)\n",
    "- waterTemperature  (in degrees Celsius)\n",
    "- salinity (in ppt)\n",
    "- pH (H)\n",
    "- turbidity (?)\n",
    "- chlorophyll (?)\n",
    "- DOSat (Dissolved Oxygen - Saturate)\n",
    "- DOMass (Dissolved Oxygen Mass Concentration)\n",
    "\n",
    "python netcdf4 documentation: http://unidata.github.io/netcdf4-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load source file location information and load copy of data to local container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f='FRF-ocean_waterquality_CS01-EXO_201612.nc'\n",
    "url_base='https://chlthredds.erdc.dren.mil/thredds/dodsC/frf/oceanography/waterquality/'\n",
    "url='CS02-EXO/CS02-EXO.ncml' #'CS01-EXO/CS01-EXO.ncml'\n",
    "\n",
    "urls=['CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201701.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201704.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201705.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201706.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201707.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201708.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201711.nc',\n",
    " 'CS01-EXO/2017/FRF-ocean_waterquality_CS01-EXO_201712.nc',\n",
    "'CS01-EXO/2018/FRF-ocean_waterquality_CS01-EXO_201801.nc',\n",
    "]\n",
    "\n",
    "nc=netCDF4.Dataset(url_base+url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Variables:\n",
    "\n",
    "Check for variables present in the data, along with their length. If the lengths differ (indicating missing data) it's probably best to just drop the variable from further consideration. If you really need it, you might be able to pad it to match the size of the other vars..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables present in the file, and their length (based on np.shape:\n",
      "latitude ()\n",
      "longitude ()\n",
      "station_name (64,)\n",
      "time (145947,)\n",
      "gaugeDepth (145947,)\n",
      "gaugeDepth_raw (145947,)\n",
      "gaugeDepthQCFlag (145947,)\n",
      "waterTemperature (145947,)\n",
      "waterTemperature_raw (145947,)\n",
      "waterTemperatureQCFlag (145947,)\n",
      "salinity (145947,)\n",
      "salinity_raw (145947,)\n",
      "salinityQCFlag (145947,)\n",
      "pH (145947,)\n",
      "pH_raw (145947,)\n",
      "pHQCFlag (145947,)\n",
      "turbidity (145947,)\n",
      "turbidity_raw (145947,)\n",
      "turbidityQCFlag (145947,)\n",
      "chlorophyll (145947,)\n",
      "chlorophyll_raw (145947,)\n",
      "chlorophyllQCFlag (145947,)\n",
      "blueGreenAlgae (145947,)\n",
      "blueGreenAlgae_raw (145947,)\n",
      "blueGreenAlgaeQCFlag (145947,)\n",
      "fDOM (145947,)\n",
      "fDOM_raw (145947,)\n",
      "fDOMQCFlag (145947,)\n",
      "DOsat (145947,)\n",
      "DOsat_raw (145947,)\n",
      "DOsatQCFlag (145947,)\n",
      "DOmassConc (145947,)\n",
      "DOmassConc_raw (145947,)\n",
      "DOmassConcQCFlag (145947,)\n",
      "batteryV (145947,)\n",
      "externalV (145947,)\n",
      "wiperCurrent (145947,)\n"
     ]
    }
   ],
   "source": [
    "print('Variables present in the file, and their length (based on np.shape:')\n",
    "for var in nc.variables:\n",
    "    print(var, np.shape(nc.variables[var]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data stream and writing a subset to a comma-separated values file - CS01 and CS02 EXO - Station Data by Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.5/site-packages/pandas/core/dtypes/cast.py:866: UserWarning: Warning: converting a masked element to nan.\n",
      "  v = np.array(v, copy=False)\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    nc=netCDF4.Dataset(url_base+url)\n",
    "    times=nc.variables['time']\n",
    "\n",
    "    csdict={\n",
    "    'water_temp' : nc.variables['waterTemperature'],\n",
    "    'salinity' : nc.variables['salinity'],\n",
    "    'pH' : nc.variables['pH'],\n",
    "    'turbidity' : nc.variables['turbidity'],\n",
    "    'chlorophyll' : nc.variables['chlorophyll'],\n",
    "    'DOsat' : nc.variables['DOsat'],\n",
    "    'DOmass' : nc.variables['DOmassConc'],\n",
    "    'bV' : nc.variables['batteryV']\n",
    "    }\n",
    "\n",
    "    dt = netCDF4.num2date(times[:],times.units)\n",
    "    df = pd.DataFrame(csdict,index=dt)\n",
    "    df.to_csv('./'+url[14:-3]+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data stream and writing a subset to a comma-separated values file - CS01 and CS02 EXO - All Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.5/site-packages/pandas/core/dtypes/cast.py:866: UserWarning: Warning: converting a masked element to nan.\n",
      "  v = np.array(v, copy=False)\n"
     ]
    }
   ],
   "source": [
    "times=nc.variables['time']\n",
    "\n",
    "csdict={\n",
    "'water_temp' : nc.variables['waterTemperature'],\n",
    "'salinity' : nc.variables['salinity'],\n",
    "'pH' : nc.variables['pH'],\n",
    "'turbidity' : nc.variables['turbidity'],\n",
    "'chlorophyll' : nc.variables['chlorophyll'],\n",
    "'DOsat' : nc.variables['DOsat'],\n",
    "'DOmass' : nc.variables['DOmassConc'],\n",
    "}\n",
    "\n",
    "dt = netCDF4.num2date(times[:],times.units)\n",
    "df = pd.DataFrame(csdict,index=dt)\n",
    "df.to_csv('./FRF_'+url[9:-5]+'_ALL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse the combined station data into files by year and month\n",
    "\n",
    "The water quality data collected by the FRF for Currituck Sound spanned three years, from 2016 through early 2018. Initially, we captured these data from the FRF Thredds server by station. Here, we parse each station's data by year and month and save to new discrete comma-separated value files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for station: FRF_CS01-EXO_ALL.csv\n",
      "   Processing year: 2016\n",
      "      No data for 01 2016\n",
      "   Processing year: 2017\n",
      "      No data for 02 2017\n",
      "      No data for 03 2017\n",
      "      No data for 10 2017\n",
      "   Processing year: 2018\n",
      "      No data for 02 2018\n",
      "      No data for 03 2018\n",
      "      No data for 04 2018\n",
      "      No data for 05 2018\n",
      "      No data for 06 2018\n",
      "      No data for 07 2018\n",
      "      No data for 08 2018\n",
      "      No data for 09 2018\n",
      "      No data for 10 2018\n",
      "      No data for 11 2018\n",
      "      No data for 12 2018\n",
      "for station: FRF_CS02-EXO_ALL.csv\n",
      "   Processing year: 2016\n",
      "      No data for 01 2016\n",
      "      No data for 02 2016\n",
      "   Processing year: 2017\n",
      "      No data for 02 2017\n",
      "      No data for 03 2017\n",
      "      No data for 11 2017\n",
      "      No data for 12 2017\n",
      "   Processing year: 2018\n",
      "      No data for 01 2018\n",
      "      No data for 02 2018\n",
      "      No data for 03 2018\n",
      "      No data for 04 2018\n",
      "      No data for 05 2018\n",
      "      No data for 06 2018\n",
      "      No data for 07 2018\n",
      "      No data for 08 2018\n",
      "      No data for 09 2018\n",
      "      No data for 10 2018\n",
      "      No data for 11 2018\n",
      "      No data for 12 2018\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "file_path='/Users/paulp/GoogleDrive/projects/CurrituckSnd/CS_Stations/'\n",
    "stations=['FRF_CS01-EXO_ALL.csv','FRF_CS02-EXO_ALL.csv']\n",
    "years=['2016','2017','2018']\n",
    "months=['01','02','03','04','05','06','07','08','09','10','11','12']\n",
    "\n",
    "for station in stations:\n",
    "    print('for station:', station)\n",
    "    dfw=pd.read_csv(file_path+station[4:8]+'/'+station, index_col='datetime')\n",
    "    for year in years:\n",
    "        print('   Processing year:', year)\n",
    "        for month in months:\n",
    "            start_date = year+'-'+month+'-01 00:00:00'\n",
    "            end_date = year+'-'+month+'-31 59:59:59.9999999'\n",
    "\n",
    "            #print(index, start_date, end_date)\n",
    "            dfo=dfw.loc[(dfw.index >= start_date) & (dfw.index <= end_date)].copy()\n",
    "            if dfo.empty:\n",
    "                print('      No data for', month, year)\n",
    "            else:\n",
    "                dfo.to_csv(file_path+station[4:8]+'/'+'FRF_'+station[4:8]+'_EXO_'+year+month+'.csv')\n",
    "        \n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spare Parts..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many ways to convert epoch to Python (day)date/time format. Since the time is UTC only the third and fourth options are useful, unless we add the +5 hour offset to adjust local (EST) to UT..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 30 19:00:18 2016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2016-12-01 00:00:18'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print( time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(nc.variables['time'][0]) ) )\n",
    "print( datetime.datetime.fromtimestamp(nc.variables['time'][0]).strftime('%c') ) \n",
    "datetime.datetime.utcfromtimestamp(nc.variables['time'][0]).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#print( time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(nc.variables['time'][0])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
